{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91496,"databundleVersionId":11802066,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Cell 1: Imports & Setup\nimport json\nimport os\nimport time\nimport random\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nimport multiprocessing as mp\nfrom concurrent.futures import ProcessPoolExecutor\nfrom sklearn.cluster import KMeans  # For object detection\nfrom scipy.ndimage import label  # Connected components\n\n# Global seed\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\n\n# Device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\n# Fake mode for eval\nfake_mode = not os.getenv('KAGGLE_IS_COMPETITION_RERUN')\nsplit = \"evaluation\" if fake_mode else \"test\"\nprint(f\"Mode: {'Eval' if fake_mode else 'Test'}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 2: Load Data\ndef load_json(path):\n    with open(path, 'r') as f:\n        return json.load(f)\n\nbase_path = '/kaggle/input/arc-prize-2025/'\nchallenges = load_json(f'{base_path}arc-agi_{split}_challenges.json')\ntask_names = list(challenges.keys())\nn_tasks = len(task_names)\nprint(f\"Loaded {n_tasks} tasks\")\n\n# For viz/debug (if fake_mode)\nif fake_mode:\n    solutions = load_json(f'{base_path}arc-agi_evaluation_solutions.json')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 3: Grid Utils & Object-Centric Rep\ndef grid_to_tensor(grid):\n    return torch.tensor(grid, dtype=torch.float32, device=device)\n\ndef tensor_to_grid(tensor):\n    return tensor.cpu().numpy().astype(int).tolist()\n\ndef detect_objects(grid):\n    \"\"\"Simple object detection: Label connected components per color.\"\"\"\n    objects = []\n    for color in np.unique(grid):\n        if color == 0: continue  # Background\n        mask = (grid == color)\n        labeled, n_objs = label(mask)\n        for obj_id in range(1, n_objs + 1):\n            obj_mask = (labeled == obj_id)\n            bbox = np.where(obj_mask)  # (rows, cols)\n            if len(bbox[0]) > 0:\n                objects.append({\n                    'color': int(color),\n                    'size': np.sum(obj_mask),\n                    'bbox': (np.min(bbox[1]), np.max(bbox[1]), np.min(bbox[0]), np.max(bbox[0]))\n                })\n    return sorted(objects, key=lambda o: o['size'], reverse=True)\n\ndef grid_hash(grid):\n    \"\"\"Hash for quick comparison.\"\"\"\n    return hash(tuple(map(tuple, grid)))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 4: Lightweight VAE Compressor (Test-Time Fit)\nclass SimpleVAE(nn.Module):\n    def __init__(self, latent_dim=16, grid_size=30):\n        super().__init__()\n        self.encoder = nn.Sequential(\n            nn.Conv2d(10, 32, 3, padding=1),  # One-hot channels\n            nn.ReLU(),\n            nn.Conv2d(32, 64, 3, padding=1),\n            nn.ReLU(),\n            nn.Flatten(),\n            nn.Linear(64 * grid_size**2, 128),\n            nn.ReLU()\n        )\n        self.mu = nn.Linear(128, latent_dim)\n        self.logvar = nn.Linear(128, latent_dim)\n        self.decoder = nn.Sequential(\n            nn.Linear(latent_dim, 128),\n            nn.ReLU(),\n            nn.Linear(128, 64 * grid_size**2),\n            nn.ReLU(),\n            nn.Unflatten(1, (64, grid_size, grid_size)),\n            nn.ConvTranspose2d(64, 32, 3, padding=1),\n            nn.ReLU(),\n            nn.ConvTranspose2d(32, 10, 3, padding=1),\n            nn.Sigmoid()\n        )\n\n    def encode(self, x):\n        h = self.encoder(x)\n        return self.mu(h), self.logvar(h)\n\n    def reparameterize(self, mu, logvar):\n        std = torch.exp(0.5 * logvar)\n        eps = torch.randn_like(std)\n        return mu + eps * std\n\n    def decode(self, z):\n        return self.decoder(z)\n\n    def forward(self, x):\n        mu, logvar = self.encode(x)\n        z = self.reparameterize(mu, logvar)\n        recon = self.decode(z)\n        return recon, mu, logvar\n\ndef vae_loss(recon, x, mu, logvar):\n    BCE = nn.functional.binary_cross_entropy(recon, x, reduction='sum')\n    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n    return BCE + KLD\n\ndef fit_vae(train_pairs, epochs=50, lr=1e-3):\n    \"\"\"Fit VAE on train pairs (one-hot grids).\"\"\"\n    model = SimpleVAE().to(device)\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n    \n    # Prep data: One-hot grids (C=10, HxW)\n    inputs = []\n    for inp, out in train_pairs:\n        inp_grid = np.array(inp)\n        out_grid = np.array(out)\n        h, w = inp_grid.shape\n        inp_onehot = np.eye(10)[inp_grid].transpose(2, 0, 1)  # (10, H, W)\n        out_onehot = np.eye(10)[out_grid].transpose(2, 0, 1)\n        inputs.append(torch.tensor(np.stack([inp_onehot, out_onehot]), dtype=torch.float32))  # Batch of 2\n    dataset = TensorDataset(torch.cat(inputs))\n    loader = DataLoader(dataset, batch_size=2, shuffle=True)\n    \n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        for batch in loader:\n            x = batch[0].to(device)  # (B=2, C=10, H, W)\n            recon, mu, logvar = model(x)\n            loss = vae_loss(recon, x, mu, logvar)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n    \n    return model\n\ndef compress_grid(model, grid):\n    \"\"\"Compress grid to latent.\"\"\"\n    grid_arr = np.array(grid)\n    h, w = grid_arr.shape\n    onehot = np.eye(10)[grid_arr].transpose(2, 0, 1)  # (10, H, W)\n    x = torch.tensor(onehot, dtype=torch.float32).unsqueeze(0).to(device)  # (1, 10, H, W)\n    model.eval()\n    with torch.no_grad():\n        mu, _ = model.encode(x)\n    return mu.squeeze().cpu().numpy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 5: DSL for Compositional Ops\nDSL_OPS = {\n    'rotate90': lambda g: np.rot90(g),\n    'mirror_h': lambda g: np.fliplr(g),\n    'mirror_v': lambda g: np.flipud(g),\n    'fill_color': lambda g, c: np.full_like(g, c) if c else g,  # Param c=0-9\n    'connect_objs': lambda g: connect_objects(g),  # Custom: Lines between objs\n    'extend_border': lambda g, d: np.pad(g, d, mode='constant'),  # Param d\n    'count_color': lambda g: np.full_like(g, len(np.unique(g))-1),  # Replace with count\n    'symmetrize': lambda g: (g + np.rot90(g)) // 2,  # Avg with rotation\n    # Add more: 20-30 primitives from ARC priors (objects, geometry)\n}\n\ndef connect_objects(grid):\n    \"\"\"Example custom op: Connect largest objs with lines.\"\"\"\n    objs = detect_objects(grid)\n    if len(objs) < 2: return grid\n    # Simple: Line between bbox centers (color=objs[0]['color'])\n    # Implementation: Bresenham line algo (simplified)\n    grid = grid.copy()\n    # Placeholder: Fill a row\n    mid_row = grid.shape[0] // 2\n    grid[mid_row, :] = objs[0]['color']\n    return grid\n\nclass DSLProgram:\n    def __init__(self, ops_seq, params_seq=None):\n        self.ops = ops_seq  # List of op names\n        self.params = params_seq or [None] * len(ops_seq)\n    \n    def apply(self, grid):\n        g = np.array(grid)\n        for op_name, param in zip(self.ops, self.params):\n            if op_name in DSL_OPS:\n                op = DSL_OPS[op_name]\n                g = op(g, param)\n        return g.tolist()\n    \n    def __str__(self):\n        return f\"{' -> '.join(self.ops)}\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 6: Neural Program Scorer (Test-Time Train)\nclass ProgramScorer(nn.Module):\n    def __init__(self, latent_dim=16, hidden_dim=64):\n        super().__init__()\n        self.scorer = nn.Sequential(\n            nn.Linear(latent_dim * 2, hidden_dim),  # Concat inp + out latents\n            nn.ReLU(),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, 1),  # Score 0-1\n            nn.Sigmoid()\n        )\n    \n    def forward(self, inp_latent, out_latent):\n        x = torch.cat([inp_latent, out_latent], dim=-1)\n        return self.scorer(x)\n\ndef fit_scorer(vae, train_pairs, epochs=100, lr=1e-2):\n    \"\"\"Train scorer on train pairs' latents.\"\"\"\n    model = ProgramScorer().to(device)\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n    \n    latents = [(compress_grid(vae, inp), compress_grid(vae, out)) for inp, out in train_pairs]\n    inp_lats = torch.tensor([l[0] for l in latents], dtype=torch.float32).to(device)\n    out_lats = torch.tensor([l[1] for l in latents], dtype=torch.float32).to(device)\n    \n    model.train()\n    for epoch in range(epochs):\n        scores = model(inp_lats, out_lats)\n        loss = nn.MSELoss()(scores, torch.ones_like(scores))  # Maximize score ~1 for good pairs\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    \n    return model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 7: Neurally-Guided DSL Search\ndef beam_search_dsl(train_pairs, test_input, vae, scorer, beam_width=20, max_depth=5, max_time=300):\n    \"\"\"Beam search guided by scorer.\"\"\"\n    start_time = time.time()\n    beam = [(DSLProgram([]), 0.0)]  # (prog, score)\n    \n    all_ops = list(DSL_OPS.keys())\n    param_ranges = {k: range(10) if 'color' in k else [1,2,3] for k in all_ops}  # Simple params\n    \n    for depth in range(max_depth):\n        if time.time() - start_time > max_time: break\n        new_beam = []\n        for prog, score in beam:\n            # Extend: Try ops + params\n            for op in all_ops:\n                for param in param_ranges.get(op, [None]):\n                    new_prog = DSLProgram(prog.ops + [op], prog.params + [param])\n                    # Score: Avg over train pairs\n                    prog_score = 0\n                    for inp, out in train_pairs:\n                        pred = new_prog.apply(inp)\n                        pred_lat = compress_grid(vae, pred)\n                        out_lat = compress_grid(vae, out)\n                        prog_score += scorer(torch.tensor(pred_lat).to(device), \n                                           torch.tensor(out_lat).to(device)).item()\n                    avg_score = prog_score / len(train_pairs)\n                    new_beam.append((new_prog, (score + avg_score) / (depth + 1)))\n        \n        # Beam prune\n        new_beam.sort(key=lambda x: x[1], reverse=True)\n        beam = new_beam[:beam_width]\n    \n    # Refine top-3: Iterative apply if needed\n    candidates = []\n    for prog, _ in beam[:3]:\n        pred = prog.apply(test_input)\n        # Simple refine: If close (e.g., 80% match to some train out), tweak\n        if np.mean([np.array_equal(pred, out) for _, out in train_pairs]) > 0.8:  # Placeholder\n            pred = refine_grid(pred)  # Custom: Minor tweaks\n        candidates.append(pred)\n    \n    return candidates[:2]  # Top-2 for attempts","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 8: Refinement & Ensemble\ndef refine_grid(grid):\n    \"\"\"Simple refinement: Smooth borders, color consistency.\"\"\"\n    grid = np.array(grid)\n    # Example: Median filter\n    from scipy.ndimage import median_filter\n    return median_filter(grid, size=2).astype(int).tolist()\n\ndef solve_single_task(task_name, challenges, solutions=None):\n    \"\"\"Solve one task.\"\"\"\n    task = challenges[task_name]\n    train_pairs = [(p['input'], p['output']) for p in task['train']]\n    test_inputs = [t['input'] for t in task['test']]\n    \n    # Fit VAE & scorer\n    vae = fit_vae(train_pairs)\n    scorer = fit_scorer(vae, train_pairs)\n    \n    outputs = []\n    for test_idx, test_input in enumerate(test_inputs):\n        candidates = beam_search_dsl(train_pairs, test_input, vae, scorer)\n        attempt1, attempt2 = candidates\n        outputs.append({\n            'attempt_1': attempt1,\n            'attempt_2': attempt2\n        })\n    \n    # Debug: Check against GT if available\n    if fake_mode and task_name in solutions:\n        gt = solutions[task_name]\n        for i, out in enumerate(outputs):\n            pred1 = np.array(out['attempt_1'])\n            pred2 = np.array(out['attempt_2'])\n            match1 = np.array_equal(pred1, gt[i]) if len(gt) > i else False\n            match2 = np.array_equal(pred2, gt[i]) if len(gt) > i else False\n            print(f\"Task {task_name} Test {i+1}: Match1={match1}, Match2={match2}\")\n    \n    return {task_name: outputs}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 9: Parallel Solver (Saturate Compute)\ndef parallel_solve(n_workers=mp.cpu_count()):\n    \"\"\"Parallelize across CPUs (Kaggle: 16+ cores).\"\"\"\n    with ProcessPoolExecutor(max_workers=n_workers) as executor:\n        futures = [executor.submit(solve_single_task, name, challenges) for name in task_names]\n        results = [f.result() for f in futures]\n    \n    # Merge\n    submission = {}\n    for res in results:\n        submission.update(res)\n    \n    # Fallback zeros for unsolved (rare here)\n    for name in task_names:\n        if name not in submission:\n            n_tests = len(challenges[name]['test'])\n            submission[name] = [{'attempt_1': [[0]], 'attempt_2': [[0]]} for _ in range(n_tests)]\n    \n    return submission\n\n# Run\nstart_time = time.time()\nsubmission = parallel_solve()\nend_time = time.time()\nprint(f\"Solved {n_tasks} tasks in {end_time - start_time:.1f}s\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 10: Generate Submission & Viz\nwith open('submission.json', 'w') as f:\n    json.dump(submission, f)\n\nprint(\"Submission saved!\")\n\n# Quick Viz (if fake_mode)\nif fake_mode:\n    import matplotlib.pyplot as plt\n    cmap = plt.cm.tab10  # 0-9 colors\n    \n    def viz_task(task_name, test_idx=0):\n        task = challenges[task_name]\n        test_in = task['test'][test_idx]['input']\n        pred1 = submission[task_name][test_idx]['attempt_1']\n        pred2 = submission[task_name][test_idx]['attempt_2']\n        gt = solutions[task_name][test_idx] if task_name in solutions else None\n        \n        fig, axs = plt.subplots(1, 4, figsize=(12, 3))\n        axs[0].imshow(test_in, cmap=cmap, vmin=0, vmax=9)\n        axs[0].set_title('Test Input')\n        axs[1].imshow(pred1, cmap=cmap, vmin=0, vmax=9)\n        axs[1].set_title('Attempt 1')\n        axs[2].imshow(pred2, cmap=cmap, vmin=0, vmax=9)\n        axs[2].set_title('Attempt 2')\n        if gt:\n            axs[3].imshow(gt, cmap=cmap, vmin=0, vmax=9)\n            axs[3].set_title('Ground Truth')\n            match1 = np.array_equal(np.array(pred1), gt)\n            match2 = np.array_equal(np.array(pred2), gt)\n            axs[1].set_title(f'Attempt 1: {\"✓\" if match1 else \"✗\"}')\n            axs[2].set_title(f'Attempt 2: {\"✓\" if match2 else \"✗\"}')\n        for ax in axs:\n            ax.set_xticks([])\n            ax.set_yticks([])\n        plt.show()\n    \n    # Viz first 3 tasks\n    for i, name in enumerate(list(submission.keys())[:3]):\n        viz_task(name)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}